"""
Google NER Service
–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è NER –Ω–∞ –±–∞–∑–µ Google Gemini.
–í—ã–ø–æ–ª–Ω—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫—É (–∫–∞–Ω–æ–Ω–∏–∑–∞—Ü–∏—é) —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ LLM,
–∏—Å–ø–æ–ª—å–∑—É—è –∑–Ω–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤–º–µ—Å—Ç–æ Wikidata/Spacy.
"""
import json
import logging
import re
from typing import List, Dict, Optional
from backend.services.llm_service import LLMService

logger = logging.getLogger(__name__)

class GoogleNERService:
    """
    NER —Å–µ—Ä–≤–∏—Å, –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ Google Gemini.
    """

    def __init__(self, llm_service: LLMService):
        self.llm = llm_service

    def load_gazetteer(self, actors: List) -> None:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∞–∫—Ç–æ—Ä–æ–≤.
        –î–ª—è GoogleNERService —ç—Ç–æ –ø–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (LLM —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞),
        –Ω–æ –º–µ—Ç–æ–¥ –Ω—É–∂–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
        """
        pass

    def extract_actors(self, text: str, **kwargs) -> List[Dict]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞ –∞–∫—Ç–æ—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏
            **kwargs: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (use_llm, thresholds –∏ —Ç.–¥. –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)

        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –∫–ª—é—á–∞–º–∏:
                - name: –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è (–æ—á–∏—â–µ–Ω–Ω–æ–µ)
                - original_name: –∫–∞–∫ –≤ —Ç–µ–∫—Å—Ç–µ
                - type: —Ç–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏
                - confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                - description: –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)
        """
        prompt = (
            "Analyze the following news text and extract named entities (Actors). "
            "Perform TWO steps in one go:\n"
            "1. EXTRACTION: Find all significant politicians, countries, companies, organizations, and persons.\n"
            "2. CLEANING & CANONICALIZATION: Return the CANONICAL name for each entity in LATIN script.\n\n"
            "Canonicalization rules:\n"
            "   - Use well-known English names if they exist:\n"
            "     'Putin', '–ü—É—Ç–∏–Ω' -> 'Vladimir Putin'\n"
            "     '–°–®–ê', '–ê–º–µ—Ä–∏–∫–∞' -> 'United States'\n"
            "     '–ë–µ–ª—ã–π –¥–æ–º' -> 'White House'\n"
            "   - For NAMES of persons, companies, places without known English equivalent:\n"
            "     Use PHONETIC transliteration (–ò–≤–∞–Ω–æ–≤ -> Ivanov, –ì–∞–∑–ø—Ä–æ–º -> Gazprom)\n"
            "   - For TITLES, positions, organization types:\n"
            "     TRANSLATE to English (–ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –æ–±–æ—Ä–æ–Ω—ã -> Ministry of Defense)\n"
            "   - Resolve genitive/declined forms to Nominative case.\n\n"
            "Return a JSON list of objects with these fields:\n"
            "- 'canonical_name': Standardized name in LATIN script (English or transliterated).\n"
            "- 'original_name': The exact text fragment found in source (any language).\n"
            "- 'type': One of ['politician', 'person', 'company', 'country', 'organization', 'int_org', 'government'].\n"
            "- 'confidence': Float 0.0-1.0.\n"
            "- 'description': Short 3-5 word identity in English.\n\n"
            "Rules:\n"
            "- EXTRACT ALL ENTITIES found in text. Be exhaustive.\n"
            "- Return up to 15 entities (focus on the most important).\n"
            "- You MUST return a JSON ARRAY (even if it has only 1 element). Never return a single JSON object.\n"
            "- If the text mentions Zelensky/Zelenskyy/–ó–µ–ª–µ–Ω—Å—å–∫–∏–π/–ó–µ–ª–µ–Ω—Å–∫–∏–π, Putin/–ü—É—Ç—ñ–Ω/–ü—É—Ç–∏–Ω, Biden/–ë–∞–π–¥–µ–Ω, you MUST include them.\n"
            "- Also include key implied state/org actors when present in the text: Ukraine, Russia, United States, NATO, United Nations, White House, Kremlin.\n"
            "- ALL canonical_name MUST use LATIN script (a-z, A-Z). Never Cyrillic or other scripts.\n"
            "- Skip generic terms like 'president' alone, 'ministry' without country.\n"
            "- Output JSON ONLY. No markdown fences.\n\n"
            f"Text:\n{text[:15000]}"
        )

        raw_response = self.llm._run(
            prompt,
            temperature=0.0,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ, —á—Ç–æ–±—ã JSON –Ω–µ —Ä–∞–∑–≤–∞–ª–∏–≤–∞–ª—Å—è
            max_output_tokens=2048,  # JSON –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–ª–∏–Ω–Ω—ã–º; –∏–∑–±–µ–≥–∞–µ–º –æ–±—Ä–µ–∑–∞–Ω–∏–π
        )
        
        # Parse JSON
        try:
            # Clean markdown if present
            cleaned = self.llm._strip_code_fences(raw_response)

            def _try_parse(s: str):
                return json.loads(s)

            data = None
            try:
                data = _try_parse(cleaned)
            except Exception:
                # Fallback 1: try raw (sometimes fences already stripped or formatting differs)
                try:
                    data = _try_parse(raw_response)
                except Exception:
                    # Fallback 2: extract first JSON array/object from the text
                    # Handles cases where model adds commentary after JSON.
                    m = re.search(r"(\[[\s\S]*\])", cleaned)
                    if not m:
                        m = re.search(r"(\{[\s\S]*\})", cleaned)
                    if m:
                        data = _try_parse(m.group(1))
                    else:
                        raise
            
            # –ò–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –≤–º–µ—Å—Ç–æ –º–∞—Å—Å–∏–≤–∞ ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            if isinstance(data, dict):
                data = [data]

            if isinstance(data, list):
                # Post-processing normalization
                results = []
                for item in data:
                    if not item.get('canonical_name'):
                        continue
                    
                    # Ensure fields exist
                    item['name'] = item['canonical_name'] # map to standard interface
                    if 'type' not in item:
                        item['type'] = 'organization'
                    
                    results.append(item)
                return results
            else:
                logger.warning(f"Google NER returned non-list JSON: {str(data)[:100]}")
                return []
                
        except json.JSONDecodeError:
            logger.error(f"Failed to parse Google NER response. Raw: {raw_response[:200]}...")
            return []
        except ValueError as e:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ API –∫–ª—é—á–∞ (–ø–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–ª—å—à–µ)
            error_str = str(e)
            if "API –ö–õ–Æ–ß–ê" in error_str or "leaked" in error_str.lower():
                logger.error(f"‚ùå Google NER: {error_str}")
                print(f"\n‚ö†Ô∏è  Google NER Service –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å: {error_str}\n")
            raise
        except Exception as e:
            error_str = str(e).lower()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫—É API –∫–ª—é—á–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ–± –æ—à–∏–±–∫–µ
            if "403" in error_str or "forbidden" in error_str or "leaked" in error_str:
                error_msg = (
                    "‚ùå –û–®–ò–ë–ö–ê API –ö–õ–Æ–ß–ê –≤ Google NER: –í–∞—à –∫–ª—é—á Google Gemini –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∏–ª–∏ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.\n"
                    "üìù –†–ï–®–ï–ù–ò–ï: –ü–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á –Ω–∞ https://aistudio.google.com/app/apikey\n"
                    "   –û–±–Ω–æ–≤–∏—Ç–µ GEMINI_API_KEY –≤ —Ñ–∞–π–ª–µ .env –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä."
                )
                logger.error(error_msg)
                print(f"\n{error_msg}\n")
                return []
            logger.error(f"Error in Google NER: {e}")
            return []
